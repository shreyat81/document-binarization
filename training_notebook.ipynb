{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6cfc697",
   "metadata": {},
   "source": [
    "# Document Binarization Model Training Notebook\n",
    "\n",
    "This notebook will guide you through training the **EfficientNet-B0 + InceptionNet-V3** model for document binarization.\n",
    "\n",
    "## ðŸ“‹ Overview\n",
    "- **Architecture**: Dual encoder (EfficientNet-B0 + InceptionNet-V3) with UNet decoder\n",
    "- **Dataset**: DIBCO cleaned and preprocessed patches (256Ã—256)\n",
    "- **Task**: Document image binarization (segmentation)\n",
    "\n",
    "## ðŸ—‚ï¸ Data Structure\n",
    "```\n",
    "split/\n",
    "  â”œâ”€â”€ train/\n",
    "  â”‚   â”œâ”€â”€ images/  (training image patches .npy)\n",
    "  â”‚   â””â”€â”€ gt/      (training ground truth .npy)\n",
    "  â”œâ”€â”€ val/\n",
    "  â”‚   â”œâ”€â”€ images/  (validation patches)\n",
    "  â”‚   â””â”€â”€ gt/\n",
    "  â””â”€â”€ test/\n",
    "      â”œâ”€â”€ images/  (test patches)\n",
    "      â””â”€â”€ gt/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11dc03db",
   "metadata": {},
   "source": [
    "## Step 1: Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa52a584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "# Import your model\n",
    "from model import DocumentBinarizationModel, CompleteBinarizationPipeline\n",
    "\n",
    "# Check PyTorch and CUDA\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c287c59",
   "metadata": {},
   "source": [
    "## Step 2: Configure Paths and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8f04d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "PROJECT_ROOT = Path(\"/Users/shreyatiwari/Documents/Soft Computing Project\")\n",
    "TRAIN_IMG_DIR = PROJECT_ROOT / \"split/train/images\"\n",
    "TRAIN_GT_DIR = PROJECT_ROOT / \"split/train/gt\"\n",
    "VAL_IMG_DIR = PROJECT_ROOT / \"split/val/images\"\n",
    "VAL_GT_DIR = PROJECT_ROOT / \"split/val/gt\"\n",
    "TEST_IMG_DIR = PROJECT_ROOT / \"split/test/images\"\n",
    "TEST_GT_DIR = PROJECT_ROOT / \"split/test/gt\"\n",
    "CHECKPOINT_DIR = PROJECT_ROOT / \"checkpoints\"\n",
    "CHECKPOINT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Training Configuration\n",
    "CONFIG = {\n",
    "    # Data\n",
    "    'batch_size': 8,  # Adjust based on GPU memory\n",
    "    'num_workers': 4,  # For data loading\n",
    "    'input_size': 256,  # Patch size (already 256x256)\n",
    "    \n",
    "    # Training\n",
    "    'num_epochs': 50,\n",
    "    'learning_rate': 1e-4,\n",
    "    'weight_decay': 1e-5,\n",
    "    'grad_clip': 1.0,\n",
    "    \n",
    "    # Loss weights\n",
    "    'bce_weight': 1.0,\n",
    "    'dice_weight': 1.0,\n",
    "    'edge_weight': 0.5,\n",
    "    \n",
    "    # Scheduler\n",
    "    'scheduler_patience': 5,\n",
    "    'scheduler_factor': 0.5,\n",
    "    \n",
    "    # Checkpointing\n",
    "    'save_every': 5,  # Save checkpoint every N epochs\n",
    "    'best_metric': 'val_f1',  # Metric to track for best model\n",
    "}\n",
    "\n",
    "print(\"Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e19f9e",
   "metadata": {},
   "source": [
    "## Step 3: Verify Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec34a378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count files in each split\n",
    "train_images = sorted(list(TRAIN_IMG_DIR.glob(\"*.npy\")))\n",
    "train_gts = sorted(list(TRAIN_GT_DIR.glob(\"*.npy\")))\n",
    "val_images = sorted(list(VAL_IMG_DIR.glob(\"*.npy\")))\n",
    "val_gts = sorted(list(VAL_GT_DIR.glob(\"*.npy\")))\n",
    "test_images = sorted(list(TEST_IMG_DIR.glob(\"*.npy\")))\n",
    "test_gts = sorted(list(TEST_GT_DIR.glob(\"*.npy\")))\n",
    "\n",
    "print(\"Dataset Statistics:\")\n",
    "print(f\"  Training:   {len(train_images)} images, {len(train_gts)} GTs\")\n",
    "print(f\"  Validation: {len(val_images)} images, {len(val_gts)} GTs\")\n",
    "print(f\"  Test:       {len(test_images)} images, {len(test_gts)} GTs\")\n",
    "print(f\"  Total:      {len(train_images) + len(val_images) + len(test_images)} patches\")\n",
    "\n",
    "# Verify matching counts\n",
    "assert len(train_images) == len(train_gts), \"Mismatch in training data!\"\n",
    "assert len(val_images) == len(val_gts), \"Mismatch in validation data!\"\n",
    "assert len(test_images) == len(test_gts), \"Mismatch in test data!\"\n",
    "print(\"\\nâœ… All image-GT pairs matched!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2837c9",
   "metadata": {},
   "source": [
    "## Step 4: Explore Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfce7b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and visualize random samples\n",
    "np.random.seed(42)\n",
    "sample_idx = np.random.randint(0, len(train_images))\n",
    "\n",
    "sample_img = np.load(train_images[sample_idx])\n",
    "sample_gt = np.load(train_gts[sample_idx])\n",
    "\n",
    "print(f\"Sample: {train_images[sample_idx].name}\")\n",
    "print(f\"Image shape: {sample_img.shape}, dtype: {sample_img.dtype}\")\n",
    "print(f\"Image range: [{sample_img.min():.3f}, {sample_img.max():.3f}]\")\n",
    "print(f\"GT shape: {sample_gt.shape}, dtype: {sample_gt.dtype}\")\n",
    "print(f\"GT range: [{sample_gt.min():.3f}, {sample_gt.max():.3f}]\")\n",
    "print(f\"GT unique values: {np.unique(sample_gt)}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axes[0].imshow(sample_img, cmap='gray')\n",
    "axes[0].set_title('Input Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(sample_gt, cmap='gray')\n",
    "axes[1].set_title('Ground Truth')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# Overlay\n",
    "axes[2].imshow(sample_img, cmap='gray', alpha=0.7)\n",
    "axes[2].imshow(sample_gt, cmap='Reds', alpha=0.3)\n",
    "axes[2].set_title('Overlay')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5167d0",
   "metadata": {},
   "source": [
    "## Step 5: Create PyTorch Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0714a18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinarizationDataset(Dataset):\n",
    "    \"\"\"Dataset for document binarization with .npy patches\"\"\"\n",
    "    \n",
    "    def __init__(self, image_dir, gt_dir, augment=False):\n",
    "        self.image_dir = Path(image_dir)\n",
    "        self.gt_dir = Path(gt_dir)\n",
    "        self.augment = augment\n",
    "        \n",
    "        # Get all image files\n",
    "        self.image_files = sorted(list(self.image_dir.glob(\"*.npy\")))\n",
    "        self.gt_files = sorted(list(self.gt_dir.glob(\"*.npy\")))\n",
    "        \n",
    "        print(f\"Loaded {len(self.image_files)} samples from {image_dir.name}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load data\n",
    "        image = np.load(self.image_files[idx]).astype(np.float32)\n",
    "        gt = np.load(self.gt_files[idx]).astype(np.float32)\n",
    "        \n",
    "        # Ensure image is in [0, 1] range\n",
    "        if image.max() > 1.0:\n",
    "            image = image / 255.0\n",
    "            \n",
    "        # Ensure GT is binary {0, 1}\n",
    "        if gt.max() > 1.0:\n",
    "            gt = (gt > 127).astype(np.float32)\n",
    "        \n",
    "        # Add channel dimension if needed\n",
    "        if len(image.shape) == 2:\n",
    "            image = image[np.newaxis, :, :]  # (1, H, W)\n",
    "        \n",
    "        if len(gt.shape) == 2:\n",
    "            gt = gt[np.newaxis, :, :]  # (1, H, W)\n",
    "        \n",
    "        # Convert to 3-channel for pretrained models\n",
    "        if image.shape[0] == 1:\n",
    "            image = np.repeat(image, 3, axis=0)  # (3, H, W)\n",
    "        \n",
    "        # Data augmentation\n",
    "        if self.augment:\n",
    "            # Random horizontal flip\n",
    "            if np.random.rand() > 0.5:\n",
    "                image = np.flip(image, axis=2).copy()\n",
    "                gt = np.flip(gt, axis=2).copy()\n",
    "            \n",
    "            # Random vertical flip\n",
    "            if np.random.rand() > 0.5:\n",
    "                image = np.flip(image, axis=1).copy()\n",
    "                gt = np.flip(gt, axis=1).copy()\n",
    "            \n",
    "            # Random 90-degree rotation\n",
    "            if np.random.rand() > 0.5:\n",
    "                k = np.random.randint(1, 4)\n",
    "                image = np.rot90(image, k, axes=(1, 2)).copy()\n",
    "                gt = np.rot90(gt, k, axes=(1, 2)).copy()\n",
    "        \n",
    "        # Convert to torch tensors\n",
    "        image = torch.from_numpy(image)\n",
    "        gt = torch.from_numpy(gt)\n",
    "        \n",
    "        return image, gt\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = BinarizationDataset(TRAIN_IMG_DIR, TRAIN_GT_DIR, augment=True)\n",
    "val_dataset = BinarizationDataset(VAL_IMG_DIR, VAL_GT_DIR, augment=False)\n",
    "test_dataset = BinarizationDataset(TEST_IMG_DIR, TEST_GT_DIR, augment=False)\n",
    "\n",
    "print(f\"\\nâœ… Datasets created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5ce9ad",
   "metadata": {},
   "source": [
    "## Step 6: Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672c6aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=True if torch.cuda.is_available() else False\n",
    ")\n",
    "\n",
    "print(\"DataLoader Statistics:\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")\n",
    "print(f\"  Test batches: {len(test_loader)}\")\n",
    "print(f\"  Batch size: {CONFIG['batch_size']}\")\n",
    "\n",
    "# Test dataloader\n",
    "sample_batch = next(iter(train_loader))\n",
    "print(f\"\\nSample batch:\")\n",
    "print(f\"  Images shape: {sample_batch[0].shape}\")\n",
    "print(f\"  GTs shape: {sample_batch[1].shape}\")\n",
    "print(f\"âœ… DataLoaders working correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f8c15d",
   "metadata": {},
   "source": [
    "## Step 7: Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b37031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the complete binarization pipeline\n",
    "model = CompleteBinarizationPipeline(in_channels=3, out_channels=1)\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"Model Information:\")\n",
    "print(f\"  Architecture: EfficientNet-B0 + InceptionNet-V3 + UNet Decoder\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"  Device: {device}\")\n",
    "\n",
    "# Test forward pass\n",
    "with torch.no_grad():\n",
    "    test_input = torch.randn(2, 3, 256, 256).to(device)\n",
    "    test_output = model(test_input)\n",
    "    print(f\"\\nTest forward pass:\")\n",
    "    print(f\"  Input shape: {test_input.shape}\")\n",
    "    print(f\"  Output shape: {test_output.shape}\")\n",
    "    print(f\"âœ… Model initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636a3865",
   "metadata": {},
   "source": [
    "## Step 8: Define Loss Function and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be69323e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedLoss(nn.Module):\n",
    "    \"\"\"Combined BCE + Dice + Edge Loss\"\"\"\n",
    "    \n",
    "    def __init__(self, bce_weight=1.0, dice_weight=1.0, edge_weight=0.5):\n",
    "        super().__init__()\n",
    "        self.bce_weight = bce_weight\n",
    "        self.dice_weight = dice_weight\n",
    "        self.edge_weight = edge_weight\n",
    "        self.bce = nn.BCEWithLogitsLoss()\n",
    "        \n",
    "    def dice_loss(self, pred, target, smooth=1e-6):\n",
    "        pred = torch.sigmoid(pred)\n",
    "        pred_flat = pred.view(-1)\n",
    "        target_flat = target.view(-1)\n",
    "        intersection = (pred_flat * target_flat).sum()\n",
    "        dice = (2. * intersection + smooth) / (pred_flat.sum() + target_flat.sum() + smooth)\n",
    "        return 1 - dice\n",
    "    \n",
    "    def edge_loss(self, pred, target):\n",
    "        \"\"\"Edge-aware loss using Sobel filters\"\"\"\n",
    "        # Sobel kernels\n",
    "        sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=torch.float32).view(1, 1, 3, 3).to(pred.device)\n",
    "        sobel_y = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=torch.float32).view(1, 1, 3, 3).to(pred.device)\n",
    "        \n",
    "        pred_sigmoid = torch.sigmoid(pred)\n",
    "        \n",
    "        # Compute edges\n",
    "        pred_edge_x = torch.nn.functional.conv2d(pred_sigmoid, sobel_x, padding=1)\n",
    "        pred_edge_y = torch.nn.functional.conv2d(pred_sigmoid, sobel_y, padding=1)\n",
    "        pred_edge = torch.sqrt(pred_edge_x**2 + pred_edge_y**2)\n",
    "        \n",
    "        target_edge_x = torch.nn.functional.conv2d(target, sobel_x, padding=1)\n",
    "        target_edge_y = torch.nn.functional.conv2d(target, sobel_y, padding=1)\n",
    "        target_edge = torch.sqrt(target_edge_x**2 + target_edge_y**2)\n",
    "        \n",
    "        return torch.nn.functional.mse_loss(pred_edge, target_edge)\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        bce = self.bce(pred, target)\n",
    "        dice = self.dice_loss(pred, target)\n",
    "        edge = self.edge_loss(pred, target)\n",
    "        \n",
    "        total = (self.bce_weight * bce + \n",
    "                 self.dice_weight * dice + \n",
    "                 self.edge_weight * edge)\n",
    "        \n",
    "        return total, {'bce': bce.item(), 'dice': dice.item(), 'edge': edge.item()}\n",
    "\n",
    "def calculate_metrics(pred, target, threshold=0.5):\n",
    "    \"\"\"Calculate accuracy, precision, recall, F1, IoU\"\"\"\n",
    "    pred_binary = (torch.sigmoid(pred) > threshold).float()\n",
    "    target_binary = target\n",
    "    \n",
    "    # True Positives, False Positives, False Negatives, True Negatives\n",
    "    tp = ((pred_binary == 1) & (target_binary == 1)).float().sum()\n",
    "    fp = ((pred_binary == 1) & (target_binary == 0)).float().sum()\n",
    "    fn = ((pred_binary == 0) & (target_binary == 1)).float().sum()\n",
    "    tn = ((pred_binary == 0) & (target_binary == 0)).float().sum()\n",
    "    \n",
    "    # Metrics\n",
    "    accuracy = (tp + tn) / (tp + fp + fn + tn + 1e-8)\n",
    "    precision = tp / (tp + fp + 1e-8)\n",
    "    recall = tp / (tp + fn + 1e-8)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "    iou = tp / (tp + fp + fn + 1e-8)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy.item(),\n",
    "        'precision': precision.item(),\n",
    "        'recall': recall.item(),\n",
    "        'f1': f1.item(),\n",
    "        'iou': iou.item()\n",
    "    }\n",
    "\n",
    "# Initialize loss\n",
    "criterion = CombinedLoss(\n",
    "    bce_weight=CONFIG['bce_weight'],\n",
    "    dice_weight=CONFIG['dice_weight'],\n",
    "    edge_weight=CONFIG['edge_weight']\n",
    ")\n",
    "\n",
    "print(\"âœ… Loss function and metrics defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13779acc",
   "metadata": {},
   "source": [
    "## Step 9: Configure Optimizer and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7febed91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=CONFIG['learning_rate'],\n",
    "    weight_decay=CONFIG['weight_decay']\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='max',  # Maximize F1 score\n",
    "    factor=CONFIG['scheduler_factor'],\n",
    "    patience=CONFIG['scheduler_patience'],\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"Optimizer Configuration:\")\n",
    "print(f\"  Type: AdamW\")\n",
    "print(f\"  Learning rate: {CONFIG['learning_rate']}\")\n",
    "print(f\"  Weight decay: {CONFIG['weight_decay']}\")\n",
    "print(f\"  Scheduler: ReduceLROnPlateau (patience={CONFIG['scheduler_patience']})\")\n",
    "print(f\"âœ… Optimizer and scheduler configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d061ddd",
   "metadata": {},
   "source": [
    "## Step 10: Training Loop Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678079e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device, epoch):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_metrics = {\n",
    "        'accuracy': 0.0, 'precision': 0.0, 'recall': 0.0, \n",
    "        'f1': 0.0, 'iou': 0.0,\n",
    "        'bce': 0.0, 'dice': 0.0, 'edge': 0.0\n",
    "    }\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=f'Epoch {epoch} [Train]')\n",
    "    \n",
    "    for batch_idx, (images, targets) in enumerate(pbar):\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss, loss_components = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), CONFIG['grad_clip'])\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        with torch.no_grad():\n",
    "            metrics = calculate_metrics(outputs, targets)\n",
    "        \n",
    "        # Update running metrics\n",
    "        running_loss += loss.item()\n",
    "        for key in running_metrics:\n",
    "            if key in metrics:\n",
    "                running_metrics[key] += metrics[key]\n",
    "            elif key in loss_components:\n",
    "                running_metrics[key] += loss_components[key]\n",
    "        \n",
    "        # Update progress bar\n",
    "        pbar.set_postfix({\n",
    "            'loss': loss.item(),\n",
    "            'f1': metrics['f1'],\n",
    "            'iou': metrics['iou']\n",
    "        })\n",
    "    \n",
    "    # Average metrics\n",
    "    num_batches = len(dataloader)\n",
    "    avg_loss = running_loss / num_batches\n",
    "    avg_metrics = {k: v / num_batches for k, v in running_metrics.items()}\n",
    "    \n",
    "    return avg_loss, avg_metrics\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion, device, epoch):\n",
    "    \"\"\"Validate the model\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_metrics = {\n",
    "        'accuracy': 0.0, 'precision': 0.0, 'recall': 0.0,\n",
    "        'f1': 0.0, 'iou': 0.0,\n",
    "        'bce': 0.0, 'dice': 0.0, 'edge': 0.0\n",
    "    }\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=f'Epoch {epoch} [Val]')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in pbar:\n",
    "            images = images.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Compute loss\n",
    "            loss, loss_components = criterion(outputs, targets)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            metrics = calculate_metrics(outputs, targets)\n",
    "            \n",
    "            # Update running metrics\n",
    "            running_loss += loss.item()\n",
    "            for key in running_metrics:\n",
    "                if key in metrics:\n",
    "                    running_metrics[key] += metrics[key]\n",
    "                elif key in loss_components:\n",
    "                    running_metrics[key] += loss_components[key]\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({\n",
    "                'loss': loss.item(),\n",
    "                'f1': metrics['f1'],\n",
    "                'iou': metrics['iou']\n",
    "            })\n",
    "    \n",
    "    # Average metrics\n",
    "    num_batches = len(dataloader)\n",
    "    avg_loss = running_loss / num_batches\n",
    "    avg_metrics = {k: v / num_batches for k, v in running_metrics.items()}\n",
    "    \n",
    "    return avg_loss, avg_metrics\n",
    "\n",
    "print(\"âœ… Training functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46d5ebb",
   "metadata": {},
   "source": [
    "## Step 11: Train the Model ðŸš€\n",
    "\n",
    "**This is the main training loop. Run this cell to start training!**\n",
    "\n",
    "Training will:\n",
    "- Save checkpoints every 5 epochs\n",
    "- Save the best model based on validation F1 score\n",
    "- Track all metrics and losses\n",
    "- Automatically adjust learning rate based on validation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5908e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training history\n",
    "history = {\n",
    "    'train_loss': [], 'val_loss': [],\n",
    "    'train_f1': [], 'val_f1': [],\n",
    "    'train_iou': [], 'val_iou': [],\n",
    "    'train_accuracy': [], 'val_accuracy': [],\n",
    "    'train_precision': [], 'val_precision': [],\n",
    "    'train_recall': [], 'val_recall': [],\n",
    "    'learning_rates': []\n",
    "}\n",
    "\n",
    "# Best model tracking\n",
    "best_metric = 0.0\n",
    "best_epoch = 0\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for epoch in range(1, CONFIG['num_epochs'] + 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Epoch {epoch}/{CONFIG['num_epochs']}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_metrics = train_one_epoch(\n",
    "        model, train_loader, criterion, optimizer, device, epoch\n",
    "    )\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_metrics = validate(\n",
    "        model, val_loader, criterion, device, epoch\n",
    "    )\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    scheduler.step(val_metrics['f1'])\n",
    "    \n",
    "    # Save history\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_f1'].append(train_metrics['f1'])\n",
    "    history['val_f1'].append(val_metrics['f1'])\n",
    "    history['train_iou'].append(train_metrics['iou'])\n",
    "    history['val_iou'].append(val_metrics['iou'])\n",
    "    history['train_accuracy'].append(train_metrics['accuracy'])\n",
    "    history['val_accuracy'].append(val_metrics['accuracy'])\n",
    "    history['train_precision'].append(train_metrics['precision'])\n",
    "    history['val_precision'].append(val_metrics['precision'])\n",
    "    history['train_recall'].append(train_metrics['recall'])\n",
    "    history['val_recall'].append(val_metrics['recall'])\n",
    "    history['learning_rates'].append(current_lr)\n",
    "    \n",
    "    # Print epoch summary\n",
    "    print(f\"\\nEpoch {epoch} Summary:\")\n",
    "    print(f\"  Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"  Train F1: {train_metrics['f1']:.4f} | Val F1: {val_metrics['f1']:.4f}\")\n",
    "    print(f\"  Train IoU: {train_metrics['iou']:.4f} | Val IoU: {val_metrics['iou']:.4f}\")\n",
    "    print(f\"  Learning Rate: {current_lr:.6f}\")\n",
    "    \n",
    "    # Save checkpoint periodically\n",
    "    if epoch % CONFIG['save_every'] == 0:\n",
    "        checkpoint_path = CHECKPOINT_DIR / f\"checkpoint_epoch_{epoch}.pth\"\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'train_loss': train_loss,\n",
    "            'val_loss': val_loss,\n",
    "            'val_f1': val_metrics['f1'],\n",
    "            'history': history\n",
    "        }, checkpoint_path)\n",
    "        print(f\"  ðŸ’¾ Checkpoint saved: {checkpoint_path.name}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_metrics['f1'] > best_metric:\n",
    "        best_metric = val_metrics['f1']\n",
    "        best_epoch = epoch\n",
    "        best_model_path = CHECKPOINT_DIR / \"best_model.pth\"\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_f1': val_metrics['f1'],\n",
    "            'val_iou': val_metrics['iou'],\n",
    "            'history': history\n",
    "        }, best_model_path)\n",
    "        print(f\"  â­ New best model saved! F1: {best_metric:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRAINING COMPLETED!\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Best validation F1: {best_metric:.4f} (Epoch {best_epoch})\")\n",
    "print(f\"Checkpoints saved in: {CHECKPOINT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d13863",
   "metadata": {},
   "source": [
    "## Step 12: Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bec1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "epochs = range(1, len(history['train_loss']) + 1)\n",
    "\n",
    "# Loss\n",
    "axes[0, 0].plot(epochs, history['train_loss'], 'b-', label='Train Loss')\n",
    "axes[0, 0].plot(epochs, history['val_loss'], 'r-', label='Val Loss')\n",
    "axes[0, 0].set_title('Loss over Epochs')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# F1 Score\n",
    "axes[0, 1].plot(epochs, history['train_f1'], 'b-', label='Train F1')\n",
    "axes[0, 1].plot(epochs, history['val_f1'], 'r-', label='Val F1')\n",
    "axes[0, 1].set_title('F1 Score over Epochs')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('F1 Score')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# IoU\n",
    "axes[1, 0].plot(epochs, history['train_iou'], 'b-', label='Train IoU')\n",
    "axes[1, 0].plot(epochs, history['val_iou'], 'r-', label='Val IoU')\n",
    "axes[1, 0].set_title('IoU over Epochs')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('IoU')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Learning Rate\n",
    "axes[1, 1].plot(epochs, history['learning_rates'], 'g-')\n",
    "axes[1, 1].set_title('Learning Rate over Epochs')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('Learning Rate')\n",
    "axes[1, 1].set_yscale('log')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(CHECKPOINT_DIR / 'training_history.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ… Training history plot saved to {CHECKPOINT_DIR / 'training_history.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bea533",
   "metadata": {},
   "source": [
    "## Step 13: Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97168661",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_checkpoint = torch.load(CHECKPOINT_DIR / \"best_model.pth\")\n",
    "model.load_state_dict(best_checkpoint['model_state_dict'])\n",
    "print(f\"Loaded best model from epoch {best_checkpoint['epoch']}\")\n",
    "print(f\"Validation F1: {best_checkpoint['val_f1']:.4f}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_metrics = {\n",
    "    'accuracy': 0.0, 'precision': 0.0, 'recall': 0.0,\n",
    "    'f1': 0.0, 'iou': 0.0\n",
    "}\n",
    "\n",
    "print(\"\\nEvaluating on test set...\")\n",
    "with torch.no_grad():\n",
    "    for images, targets in tqdm(test_loader, desc='Testing'):\n",
    "        images = images.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss, _ = criterion(outputs, targets)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = calculate_metrics(outputs, targets)\n",
    "        for key in test_metrics:\n",
    "            test_metrics[key] += metrics[key]\n",
    "\n",
    "# Average metrics\n",
    "num_batches = len(test_loader)\n",
    "test_loss /= num_batches\n",
    "for key in test_metrics:\n",
    "    test_metrics[key] /= num_batches\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TEST SET RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"  Loss: {test_loss:.4f}\")\n",
    "print(f\"  Accuracy: {test_metrics['accuracy']:.4f}\")\n",
    "print(f\"  Precision: {test_metrics['precision']:.4f}\")\n",
    "print(f\"  Recall: {test_metrics['recall']:.4f}\")\n",
    "print(f\"  F1 Score: {test_metrics['f1']:.4f}\")\n",
    "print(f\"  IoU: {test_metrics['iou']:.4f}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d50af3",
   "metadata": {},
   "source": [
    "## Step 14: Visualize Predictions on Test Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d1b138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions on random test samples\n",
    "model.eval()\n",
    "num_samples = 4\n",
    "sample_indices = np.random.choice(len(test_dataset), num_samples, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(num_samples, 4, figsize=(16, 4*num_samples))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, sample_idx in enumerate(sample_indices):\n",
    "        image, gt = test_dataset[sample_idx]\n",
    "        image_batch = image.unsqueeze(0).to(device)\n",
    "        \n",
    "        # Predict\n",
    "        output = model(image_batch)\n",
    "        pred = torch.sigmoid(output).cpu().squeeze().numpy()\n",
    "        pred_binary = (pred > 0.5).astype(np.float32)\n",
    "        \n",
    "        # Convert to numpy for visualization\n",
    "        image_np = image[0].cpu().numpy()  # First channel for grayscale\n",
    "        gt_np = gt.squeeze().cpu().numpy()\n",
    "        \n",
    "        # Plot\n",
    "        axes[idx, 0].imshow(image_np, cmap='gray')\n",
    "        axes[idx, 0].set_title('Input Image')\n",
    "        axes[idx, 0].axis('off')\n",
    "        \n",
    "        axes[idx, 1].imshow(gt_np, cmap='gray')\n",
    "        axes[idx, 1].set_title('Ground Truth')\n",
    "        axes[idx, 1].axis('off')\n",
    "        \n",
    "        axes[idx, 2].imshow(pred, cmap='gray')\n",
    "        axes[idx, 2].set_title('Prediction (Probability)')\n",
    "        axes[idx, 2].axis('off')\n",
    "        \n",
    "        axes[idx, 3].imshow(pred_binary, cmap='gray')\n",
    "        axes[idx, 3].set_title('Prediction (Binary)')\n",
    "        axes[idx, 3].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(CHECKPOINT_DIR / 'test_predictions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"âœ… Test predictions saved to {CHECKPOINT_DIR / 'test_predictions.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3ebaf4",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Training Complete!\n",
    "\n",
    "### Summary\n",
    "- âœ… Model trained successfully with EfficientNet-B0 + InceptionNet-V3\n",
    "- âœ… Best model saved based on validation F1 score\n",
    "- âœ… Training history and predictions visualized\n",
    "- âœ… All checkpoints saved in `checkpoints/` directory\n",
    "\n",
    "### Next Steps\n",
    "1. **Test on new images**: Use `inference.py` to test on unseen documents\n",
    "2. **Fine-tune hyperparameters**: Adjust learning rate, batch size, loss weights\n",
    "3. **Analyze errors**: Look at difficult samples where the model struggles\n",
    "4. **Deploy**: Use the best model for production inference\n",
    "\n",
    "### Files Generated\n",
    "- `checkpoints/best_model.pth` - Best model checkpoint\n",
    "- `checkpoints/checkpoint_epoch_*.pth` - Periodic checkpoints\n",
    "- `checkpoints/training_history.png` - Training curves\n",
    "- `checkpoints/test_predictions.png` - Sample predictions"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
